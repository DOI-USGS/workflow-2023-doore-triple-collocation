{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40e77ba-d6e7-4f9c-93cb-43ecd70f7f60",
   "metadata": {},
   "source": [
    "# Relative Bias Estimates between Data Sets\n",
    "\n",
    "Now that we have computed the error variances in the [TC notebook](2_TC_application.ipynb) and covariances in the [EC notebook](3_EC_application.ipynb), let's compare the differences (i.e., relative bias) between data sets over all time/seasons. We can then compare this relative bias to the error variances. If the bias is on a smaller scale than errors, it would then show that bias is not as important as the error variance in ET data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5892d-4c23-4647-8758-26382db9d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import itertools\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df4dc4-b6e3-40eb-a198-528766f10d0a",
   "metadata": {},
   "source": [
    "## Combine Data Sets in Xarray\n",
    "First, we need to load in our ET data sets and limit them to a common date range. Since biases will be between two data sets, we will restrict the data ranges of all data sets to have the beginning date of the second oldest starting date and ending data of the second most recent ending date. This choice allows us to save some memory usage, while also utilizing the largest amount of data. When computing biases for data sets with a more restricted date range, the missing data should propagate and not give us a bias on those dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d532e7dc-7f1d-4080-b40d-7922a29259c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../Data/ssebop/ssebop_aet_regridded.nc',\n",
    "         '../Data/gleam/gleam_aet.nc',\n",
    "         '../Data/era5/era5_aet_regridded.nc',\n",
    "         '../Data/nldas/nldas_aet_regridded.nc',\n",
    "         '../Data/terraclimate/terraclimate_aet_regridded.nc',        \n",
    "         '../Data/wbet/wbet_aet_regridded.nc',\n",
    "         ]\n",
    "dataset_name = ['SSEBop', 'GLEAM', 'ERA5', 'NLDAS', 'TerraClimate', 'WBET']\n",
    "\n",
    "date_ranges = {}\n",
    "for file, name in zip(files, dataset_name):\n",
    "    ds_temp = xr.open_dataset(file, engine='netcdf4', chunks={'lon': -1, 'lat': -1, 'time': -1})\n",
    "    date_ranges[name] = [ds_temp.time.min().values, ds_temp.time.max().values]\n",
    "\n",
    "# Take the third oldest start and third most recent end dates\n",
    "date_range = [np.sort(np.array(list(date_ranges.values()))[:, 0])[1],\n",
    "              np.sort(np.array(list(date_ranges.values()))[:, 1])[-2]]\n",
    "date_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d64ebc9-ac5e-40ae-b0ad-7151943a51c1",
   "metadata": {},
   "source": [
    "Using the date range, we can now combine all of the data sets into a single `Xarray` `DataSet` for easy computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880c50e-d29c-46e6-a338-39860d1aa474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    \"\"\"\n",
    "    Keep only the specified time range for each file.\n",
    "    \"\"\"\n",
    "    return ds.sel(time=slice(date_range[0], date_range[1]))\n",
    "\n",
    "ds = xr.open_mfdataset(files, engine='netcdf4', preprocess=preprocess, combine='nested', concat_dim='dataset_name')\n",
    "ds = ds.assign_coords({'dataset_name': dataset_name})\n",
    "ds.dataset_name.attrs['description'] = 'Dataset name'\n",
    "\n",
    "# Need time as first index for TC computation\n",
    "ds = ds.transpose('time', ...)\n",
    "# The data set is less than 1GiB, so let's read it into memory vs keeping as a dask array\n",
    "ds = ds.compute()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a730d-5436-41e7-9d7e-e6f1c9a79284",
   "metadata": {},
   "source": [
    "## Relative Bias Estimation\n",
    "\n",
    "Next, we will want to compute the relative bias for all 15 possible pairs of our six data sets. So, let's generate those pairs or combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79f241-28b3-4964-9c27-f58e15dc1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of the combinations\n",
    "combos = list(itertools.combinations(dataset_name, 2))\n",
    "combos = [list(combo) for combo in combos]\n",
    "combos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8056b43-5244-4eb6-b245-81b52ee44c5d",
   "metadata": {},
   "source": [
    "Now that we have our data set combinations, let's compute the relative biases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0db85-2221-4de0-8e5e-2f0bc042e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_diff = []\n",
    "for combo in combos:\n",
    "    ds_combo = ds.sel(dataset_name=combo)\n",
    "\n",
    "    da_combo_diff = ds_combo.aet.diff('dataset_name')\n",
    "    da_combo_diff = da_combo_diff.squeeze('dataset_name').drop_vars('dataset_name')\n",
    "\n",
    "    ds_combo_diff = xr.Dataset(data_vars={'difference': da_combo_diff},\n",
    "                               coords={'dataset_pairs': [' '.join(combo)],\n",
    "                                       'time': ds.time, 'lat': ds.lat, 'lon': ds.lon})\n",
    "    ds_diff.append(ds_combo_diff)\n",
    "\n",
    "ds_diff = xr.concat(ds_diff, dim='dataset_pairs')\n",
    "\n",
    "ds_diff.difference.attrs['description'] = 'Difference between two data sets listed in dataset_pairs'\n",
    "ds_diff.dataset_pairs.attrs['description'] = 'Dataset pairs used in difference.'\n",
    "ds_diff.difference.attrs['units'] = 'mm.month-1'\n",
    "\n",
    "ds_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c90e36-cb5c-434a-9ce6-68b2fb89e565",
   "metadata": {},
   "source": [
    "Now, let's see how the resulting biases look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8c0fc-2036-423b-9a47-70cd1f88e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = ds_diff.difference.hvplot(groupby=['dataset_pairs', 'time'], geo=True, coastline=True,\n",
    "                                clim=(-75, 75), cmap='PuOr').opts(frame_width=500)\n",
    "\n",
    "pn.panel(plt, widget_location='top')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5299e-980b-441b-bb39-3558ce5fdfe8",
   "metadata": {},
   "source": [
    "## Relative Bias Discussion\n",
    "\n",
    "Looking at the biases, we can see a large temporal variation in each estimate. However, while being able to check this relative bias temporally is in itself interesting, our goal is to compare the bias with the error variances estimated from TC. Therefore, we need a single bias product that does not vary with time. To that end, we will temporally average the bias estimates and use these averages to compare with the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc044649-ad03-4df6-a12a-41d18c01f839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want to ignore all of the sqrt and log warnings with negative values\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Create list of seasons\n",
    "seasons = ['All'] + list(np.unique(ds.time.dt.season))\n",
    "\n",
    "ds_mean_bias = []\n",
    "ds_median_bias = []\n",
    "ds_std_bias = []\n",
    "ds_count_bias = []\n",
    "for season in seasons:\n",
    "    if season == 'All':\n",
    "        ds_season = ds_diff\n",
    "    else:\n",
    "        ds_season = ds_diff.isel(time=(ds.time.dt.season == season))\n",
    "\n",
    "    mean_bias = ds_season.difference.mean(dim='time', skipna=True, keep_attrs=True).expand_dims(season=[season])\n",
    "    mean_bias.name = 'mean_bias'\n",
    "    mean_bias.attrs['description'] = 'Mean bias estimate for all common time steps between data sets.'\n",
    "    mean_bias.attrs['units'] = 'mm.month-1'\n",
    "    ds_mean_bias.append(mean_bias)\n",
    "\n",
    "    median_bias = ds_season.difference.median(dim='time', skipna=True, keep_attrs=True).expand_dims(season=[season])\n",
    "    median_bias.name = 'median_bias'\n",
    "    median_bias.attrs['description'] = 'Median bias estimate for all common time steps between data sets.'\n",
    "    median_bias.attrs['units'] = 'mm.month-1'\n",
    "    ds_median_bias.append(median_bias)\n",
    "\n",
    "    std_bias = ds_season.difference.std(dim='time', ddof=1, skipna=True, keep_attrs=True).expand_dims(season=[season])\n",
    "    std_bias.name = 'std_bias'\n",
    "    std_bias.attrs['description'] = 'Standard deviation of the bias estimates for all common time steps between data sets.'\n",
    "    std_bias.attrs['units'] = 'mm.month-1'\n",
    "    ds_std_bias.append(std_bias)\n",
    "\n",
    "    count_bias = np.isfinite(ds_season.difference).sum(dim='time').expand_dims(season=[season])\n",
    "    count_bias.name = 'Counts'\n",
    "    count_bias.attrs['description'] = ('Number of datasets used in the average bias '\n",
    "                                         'estimates (i.e., number of finite time values in a given pixel).')\n",
    "    count_bias.attrs['units'] = 'counts'\n",
    "    ds_count_bias.append(count_bias)\n",
    "\n",
    "ds_mean_bias = xr.concat(ds_mean_bias, dim='season')\n",
    "ds_median_bias = xr.concat(ds_median_bias, dim='season')\n",
    "ds_std_bias = xr.concat(ds_std_bias, dim='season')\n",
    "ds_count_bias = xr.concat(ds_count_bias, dim='season')\n",
    "\n",
    "# Compile these DataSets into one and save\n",
    "bias_averages = xr.merge([ds_mean_bias, ds_median_bias, ds_std_bias, ds_count_bias], join='exact')\n",
    "_ = bias_averages.to_netcdf(path='../Data/compiled_avg_bias.nc', format='NETCDF4', engine='netcdf4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60159322-1f36-47d0-8e11-0636a9e6387b",
   "metadata": {},
   "source": [
    "Now that we have our average biases, let's generate some plots that show how the biases compare to the error standard deviations. If we see that the bias is commonly much lower than the errors, then it indicates that the uncertainty in ET data sets are more important than the relative biases between them. Conversely, if the bias is larger, then the choice of ET data set could have implications and propagated biases on resulting products modeled from the ET data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9046c33-4c7d-4ee7-b34e-151b1f3c8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_est_averages = xr.open_dataset('../Data/compiled_TC_avg_errs.nc', engine='netcdf4')\n",
    "\n",
    "def mean_diff_plots(dataset_pairs='SSEBop GLEAM', season='All'):\n",
    "    tc_avg_season = tc_est_averages.sel(season=season)\n",
    "    bias_avg_season = bias_averages.sel(season=season)\n",
    "    \n",
    "    ds_median = bias_avg_season.median_bias.sel(dataset_pairs=dataset_pairs)\n",
    "    ds_median_abs = abs(ds_median)\n",
    "    ds_median_abs.name = 'absolute difference'\n",
    "    ds1_error = tc_avg_season.median_error.sel(dataset_name=dataset_pairs.split()[0])\n",
    "    ds2_error = tc_avg_season.median_error.sel(dataset_name=dataset_pairs.split()[1])\n",
    "    ds1_bias_var_diff = (ds1_error - ds_median_abs)/ds1_error * 100\n",
    "    ds2_bias_var_diff = (ds2_error - ds_median_abs)/ds2_error * 100\n",
    "\n",
    "    plt = (ds_median.hvplot(geo=True, coastline=True, clim=(-50, 50), cmap='PuOr',\n",
    "                            title='Median Difference of '+dataset_pairs.split()[0]+' - '+dataset_pairs.split()[1]+' (Bias)').opts(frame_width=500)\n",
    "           + ds_median_abs.hvplot(geo=True, coastline=True, clim=(0, 50), cmap='Purples',\n",
    "                                  title='Median Absolute Difference of '+dataset_pairs.split()[0]+' - '+dataset_pairs.split()[1]+' (Absolute Bias)').opts(frame_width=500)\n",
    "           # + ds1_error.hvplot(geo=True, coastline=True, clim=(0, 50), cmap='Purples',\n",
    "           #                    title='Median Error Standard Deviation for '+dataset_pairs[0]).opts(frame_width=500)\n",
    "           # + ds2_error.hvplot(geo=True, coastline=True, clim=(0, 50), cmap='Purples',\n",
    "           #                    title='Median Error Standard Deviation for '+dataset_pairs[1]).opts(frame_width=500)\n",
    "           + ds1_bias_var_diff.hvplot(geo=True, coastline=True, clim=(-100, 100), cmap='PuOr',\n",
    "                                      title='Percent Difference of Median Error of '+dataset_pairs.split()[0]+' and Absolute Bias').opts(frame_width=500)\n",
    "           + ds2_bias_var_diff.hvplot(geo=True, coastline=True, clim=(-100, 100), cmap='PuOr',\n",
    "                                      title='Percent Difference of Median Error of '+dataset_pairs.split()[1]+' and Absolute Bias').opts(frame_width=500))\n",
    "\n",
    "    return plt.cols(2)\n",
    "\n",
    "# Limit combo options to have W as the common base\n",
    "dataset_pairs_widget = pn.widgets.Select(name=\"dataset_pairs\", value=\"SSEBop GLEAM\", options=list(ds_diff.dataset_pairs.data))\n",
    "season_widget = pn.widgets.Select(name=\"season\", value=\"All\", options=['All', 'DJF', 'MAM', 'JJA', 'SON'])\n",
    "\n",
    "bound_plot = pn.bind(mean_diff_plots, dataset_pairs=dataset_pairs_widget, season=season_widget)\n",
    "\n",
    "pn.Column(dataset_pairs_widget, season_widget, bound_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509b93b-dbd1-4313-a3c1-8d671e8cc8b1",
   "metadata": {},
   "source": [
    "From these results, we can notice several things. One is the gerneral trends in average bias. When looking at all the pairs, we can see that SSEBop typically estimates larger ET values compare to all other data sets except in the Southeast, whereas ERA5 typically has lower ET estimates overall. This general comparison can help us understand the overall spatial difference between the six data sets. While we could continue to check this out in more detail, we want to focus on the comparison between the bias and the error standard deviations. One thing to reiterate when comparing the biases to their error estimates is that the errors are likely lower limits on the uncertainty and the bias is a median estimate. Therefore, if we see that the errors are larger than the bias, this is likely true for the majority of the monthly ET data (i.e., 50% of the monthly relative bias is below the median). So, looking at the percent differences between the errors and the bias for each data set we can see that:\n",
    "\n",
    "1. SSEBop - The errors are typically larger than the bias when compared to all data sets in the central US, whereas the bias seems to be larger in the Rocky Mountain region. As for the eastern US, depending on the data set pair, the bias or the error could be larger. Looking at seasonal data, the bias is almost always larger throughout CONUS, besides in the Fall, when the errors can be larger in the central US.\n",
    "2. GLEAM - The errors are typically larger than the bias when compared to all data sets in the western US (excluding the Pacific Northwest), whereas the bias is generally larger in the eastern half of CONUS. Looking at seasonal data, there is no general trends of the bias or uncertainty being larger in throughout each season besides winter, as the visual trends are quite noisy. For winter, the bias is clearly larger for most of CONUS.\n",
    "3. ERA5 - The errors are typically larger than the bias for all data sets throughout CONUS. Some data set pairs show the bias being larger near coastal regions, but not the entire CONUS coast. As for seasonal trends, the bias is larger throughout for both winter and spring, but summer and fall show the errors are larger in the southern US for most data set pairs and sometimes larger in the northern US.\n",
    "4. NLDAS - The bias is larger for the the eastern US, especially the southeastern US. Otherwise, the errors are typically larger in the centeral and western US. In terms of seasonal variation, the bias dominates in the winter and spring. During the summer, the southwest and centeral US can have larger errors compared to the bias, and same goes with fall, but the bias typically dominates more compared to the summer.\n",
    "5. TerraClimate - The errors are larger than the bias for all of CONUS except for the southeast and the coastal Pacific northwest. When looking at the seasons, the errors dominate throughout all seasons in the centeral US and Great Plains. In summer and fall, the error dominating the bias also occurs in the southwest. Besides these, the bias dominates, especially in the eastern US.\n",
    "6. WBET - On average, the errors dominate the bias, but there is some variation between data sets. For the seasons, the bias is larger for the winter and spring months excluding the north central US. For the summer and fall, the errors can be larger depending on the data set pair, with all but SSEBop and TerraClimate pairs showing larger errors throughout most of CONUS.\n",
    "\n",
    "From these summaries, we can draw a few conclusions about the comparison between the bias and uncertainty. In general, most data sets do well when looking at all the data. Each have certain regions where the bias between all data sets is larger than the given data set's uncertainty. These regions indicate one of two things with the data set, either 1) the lack of consensus with the other data sets shows the ET data set is likely truly biased in these regions, or 2) the uncertainty is underestimated in these regions. Either way, having a commonly larger bias compared to the uncertainty indicates that the ET data set is not optimally performing in these given regions. As for seasonalities, winter normally has larger bias compared to uncertainty. However, this is to be expected as the winter uncertainties should be smaller compared to other seasons due to winter typically having low to no ET. For the other seasons, it varies whether the bias or uncertainty is larger based on data set and the corresponding bias pair. Therefore, broad conclusions for these months are harder to draw. Overall though, these bias and error comparisons can help us better understand the strengths and commonalities of each data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "et_tc",
   "language": "python",
   "name": "et_tc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
